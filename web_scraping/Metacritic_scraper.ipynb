{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TV urls (series overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e5L-PH0LJDv2"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from time import time\n",
    "from random import randint\n",
    "from IPython.core.display import clear_output\n",
    "from warnings import warn\n",
    "import pandas as pd\n",
    "\n",
    "# Use your own User-Agent\n",
    "headers = {'User-Agent':'Mozilla/5.0 (X11; Ubuntu; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36 RuxitSynthetic/1.0 v316542848 t18859'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cqQfn23-vSiu"
   },
   "outputs": [],
   "source": [
    "# Get the tv urls for the overview details page\n",
    "# Lists to store the scraped data in\n",
    "tv_urls = []\n",
    "\n",
    "# Get series urls - the overview of the series \n",
    "# Preparing the monitoring of the loop\n",
    "start_time = time()\n",
    "req = 0\n",
    "\n",
    "# The loop\n",
    "categories = ['new-series', 'returning-series', 'special-event']\n",
    "# For every category\n",
    "for category in categories:\n",
    "    if category=='returning-series':\n",
    "    pages = range(7)\n",
    "    else:\n",
    "    pages = [0]\n",
    "\n",
    "    # For every page\n",
    "    for page in pages:\n",
    "    if page==0:\n",
    "        response = requests.get('https://www.metacritic.com/browse/tv/release-date/'+category+'/date', headers=headers)\n",
    "    else:\n",
    "        response = requests.get('https://www.metacritic.com/browse/tv/release-date/'+category+'/date?page='+str(page), headers=headers)\n",
    "\n",
    "    # Pause the loop\n",
    "    sleep(randint(8,15))\n",
    "\n",
    "    # Monitor the requests\n",
    "    req += 1\n",
    "    elapsed_time = time() - start_time\n",
    "    print('Request:{}; Frequency: {} requests/s'.format(req, req/elapsed_time))\n",
    "    clear_output(wait = True)\n",
    "\n",
    "    # Throw a warning for non-200 status codes\n",
    "    if response.status_code != 200:\n",
    "        warn('Request: {}; Status code: {}'.format(req, response.status_code))\n",
    "\n",
    "    # Break the loop if the number of requests is greater than expected\n",
    "    if req > 10:\n",
    "        warn('Number of requests was greater than expected.')\n",
    "\n",
    "    # Parse the content of the request with BeautifulSoup\n",
    "    page_html = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Select all the tvshow containters from a single page\n",
    "    first_show = page_html.find('li', class_='product season_product first_product')\n",
    "    show_containers = page_html.find_all('li', class_='product season_product')\n",
    "    last_show = page_html.find('li', class_='product season_product last_product')\n",
    "\n",
    "    # Extract the page of tvshow from individual tvshow container\n",
    "    # First container\n",
    "    # TV Show page url\n",
    "    show_url = first_show.a['href'].split('/season-', 1)[0]\n",
    "    if show_url not in tv_urls:\n",
    "        tv_urls.append(show_url)\n",
    "\n",
    "    # Middle containers\n",
    "    for container in show_containers:\n",
    "        show_url = container.a['href'].split('/season-', 1)[0]\n",
    "        if show_url not in tv_urls:\n",
    "        tv_urls.append(show_url)\n",
    "\n",
    "    # Last container\n",
    "    # TV Show page url\n",
    "    show_url = last_show.a['href'].split('/season-', 1)[0]\n",
    "    if show_url not in tv_urls:\n",
    "        tv_urls.append(show_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CDIyqYVzVM56"
   },
   "outputs": [],
   "source": [
    "# Save tv_urls into csv, so that we don't need to make the future requests\n",
    "tv_urls_df = pd.DataFrame({'tv_url': tv_urls})\n",
    "tv_urls_df.to_csv('tv_urls.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TV series overview ratings & reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "Ek0nQyMSClKP",
    "outputId": "2e40d18d-8af9-4ebb-b0ee-c93596d4d2fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/tv/love-fraud', '/tv/in-my-skin']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the `tv_urls.csv` file\n",
    "tv_urls = pd.read_csv('tv_urls.csv')\n",
    "\n",
    "# Save tv_url in a list\n",
    "tv_urls_list = tv_urls['tv_url'].tolist()\n",
    "tv_urls_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TBNQMMy4Dt4_"
   },
   "outputs": [],
   "source": [
    "# Loop through all tv_urls and get title, date, user names, user ratings, and user reviews\n",
    "# This takes the information for the overview of the tv series\n",
    "\n",
    "# Lists to store the scraped data\n",
    "titles = []\n",
    "dates = []\n",
    "user_names = []\n",
    "ratings = []\n",
    "reviews = []\n",
    "review_dates = []\n",
    "\n",
    "\n",
    "# Functions to make the code more efficient\n",
    "def monitor_loop():\n",
    "    \"\"\"\n",
    "    Function to pause the loop and monitor the requests\n",
    "    \"\"\"\n",
    "    # Pause the loop\n",
    "    sleep(randint(10,30))\n",
    "    \n",
    "    # Throw a warning for non-200 status codes\n",
    "    if response.status_code != 200:\n",
    "        message = warn('Status code: {}'.format(response.status_code))\n",
    "        return message\n",
    "\n",
    "def get_title_date():\n",
    "    \"\"\"\n",
    "    Gets the title and the release date\n",
    "    \"\"\"\n",
    "    # The title\n",
    "    title = page_html.h1.text\n",
    "    # The release date\n",
    "    release_date = page_html.find('span', class_='release_date').find('span', class_=None).text\n",
    "    return title, release_date\n",
    "\n",
    "def get_user_rating_review():\n",
    "    \"\"\"\n",
    "    Gets the user name, rating, review, and review_date\n",
    "    Adds the scraped data to the lists\n",
    "    \"\"\"\n",
    "    # Add the title to the list\n",
    "    titles.append(title)\n",
    "    # Add the release date to the list\n",
    "    dates.append(release_date)\n",
    "    # Get the user name and add it to the list\n",
    "    user_name = container.a.text\n",
    "    user_names.append(user_name)\n",
    "    # Get the rating and add it to the list\n",
    "    rating = container.find('div', class_='left fl').text.replace('\\n','')\n",
    "    ratings.append(rating)\n",
    "    # Get the review and add it to the list\n",
    "    review = container.find('div', class_='review_body').text.replace('\\n', '')\n",
    "    reviews.append(review)\n",
    "    # Get the review date and add it to the list\n",
    "    review_date = container.find('span', class_='date').text\n",
    "    review_dates.append(review_date)\n",
    "    return titles, dates, user_names, ratings, reviews, review_dates\n",
    "    \n",
    "# The loop\n",
    "# For each url of the series\n",
    "for url in tv_urls_list:\n",
    "    # Monitor the url scraped\n",
    "    print(url)\n",
    "    clear_output(wait = True)\n",
    "    \n",
    "    # Get the html page\n",
    "    response = requests.get('https://www.metacritic.com'+url+'/user-reviews', headers=headers)\n",
    "    # Monitor the loop\n",
    "    monitor_loop()\n",
    "    # Parse the content of the request with BeautifulSoup\n",
    "    page_html = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "    # Get the reviews containers\n",
    "    review_containers = page_html.find_all('div', class_='review pad_top1')\n",
    "    \n",
    "    # If any review_container, get the data\n",
    "    if review_containers:\n",
    "        # The title and release date\n",
    "        title, release_date = get_title_date()\n",
    "        # Get the data for each review\n",
    "        for container in review_containers:\n",
    "            titles, dates, user_names, ratings, reviews, review_dates = get_user_rating_review()\n",
    "\n",
    "        # Go to the next page (if any)\n",
    "        # The while loop runs only if there is a `next` button\n",
    "        if page_html.find('span', class_='flipper next'):\n",
    "            # Get the page url\n",
    "            next_page = page_html.find('span', class_='flipper next').a\n",
    "            while next_page:\n",
    "                next_page_url = next_page['href']\n",
    "                # Download the next page\n",
    "                response = requests.get('https://www.metacritic.com'+next_page_url, headers=headers)\n",
    "                # Monitor the loop\n",
    "                monitor_loop()\n",
    "                # Parse the content of the request with BeautifulSoup\n",
    "                page_html = BeautifulSoup(response.text, 'html.parser')\n",
    "                # The reviews containers\n",
    "                review_containers = page_html.find_all('div', class_='review pad_top1')\n",
    "                # The data for each review\n",
    "                for container in review_containers:\n",
    "                    get_user_rating_review()\n",
    "                # Get the page url\n",
    "                # The while loop stops if next_page==None\n",
    "                next_page = page_html.find('span', class_='flipper next').a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save series ratings into csv, so that we don't need to make future requests\n",
    "series_ratings = pd.DataFrame({\n",
    "    'title' : titles,\n",
    "    'release_date' : dates,\n",
    "    'user_name' : user_names,\n",
    "    'rating' : ratings,\n",
    "    'review' : reviews,\n",
    "    'review_date' : review_dates\n",
    "})\n",
    "\n",
    "series_ratings.to_csv('series_ratings.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Season URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the season urls\n",
    "season_urls = []\n",
    "\n",
    "for url in tv_urls_list:\n",
    "    response = requests.get('https://www.metacritic.com'+url, headers=headers)\n",
    "    # Monitor the loop\n",
    "    monitor_loop()\n",
    "    # Parse the content of the request with BeautifulSoup\n",
    "    page_html = BeautifulSoup(response.text, 'html.parser')\n",
    "    # Get the url containers\n",
    "    season_urls_containers = page_html.find_all('li', class_='ep_guide_season')\n",
    "    # Get the season url\n",
    "    for container in season_urls_containers:\n",
    "        season_url = container.a['href']\n",
    "        season_urls.append(season_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the seasons urls into csv, so that we don't need to make future requests\n",
    "# Save tv_urls into csv, so that we don't need to make the future requests\n",
    "season_urls_df = pd.DataFrame({'season_url': season_urls})\n",
    "season_urls_df.to_csv('season_urls.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Metacritic-scraper.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
